# ν†µν•© μ²λ¦¬ ν”λ΅μ° κ°€μ΄λ“

## π― ν•µμ‹¬ ν”λ΅μ°

```mermaid
sequenceDiagram
    participant Client as μ›Ή ν”„λ΅ νΈμ—”λ“
    participant Gateway as LLM Gateway (1111)
    participant MCP as MCP Server (9999)
    participant LLM as LLM API (OpenAI/Anthropic)
    participant Redis as Redis (3333)

    Client->>Gateway: POST /api/v1/process<br/>Headers: Authorization: Bearer [client_token]<br/>Body: {prompt, mcpTools, ...}
    
    Gateway->>Redis: API Key κ²€μ¦
    Redis-->>Gateway: κ²€μ¦ μ™„λ£
    
    Gateway->>Gateway: ν΄λΌμ΄μ–ΈνΈ ν† ν° μ¶”μ¶
    
    alt MCP λ„κµ¬ μ‚¬μ© μ‹
        Gateway->>MCP: ν΄λΌμ΄μ–ΈνΈ ν† ν°μΌλ΅ μΈμ¦<br/>Bearer [client_token]
        MCP-->>Gateway: μΈμ¦ μ„±κ³µ
        
        loop κ° MCP λ„κµ¬
            Gateway->>MCP: λ„κµ¬ μ‹¤ν–‰ (get_appraisals λ“±)
            MCP-->>Gateway: λ°μ΄ν„° λ°ν™
        end
        
        Gateway->>Gateway: ν”„λ΅¬ν”„νΈμ— MCP λ°μ΄ν„° μ¶”κ°€
    end
    
    Gateway->>LLM: κ°•ν™”λ ν”„λ΅¬ν”„νΈ μ „μ†΅
    LLM-->>Gateway: AI μ‘λ‹µ
    
    Gateway->>Redis: μ»¨ν…μ¤νΈ μ €μ¥
    
    Gateway-->>Client: ν†µν•© μ‘λ‹µ<br/>{llmResponse, mcpData, context}
```

## π”„ μ‹¤μ  μ²λ¦¬ νλ¦„

### 1οΈβƒ£ ν΄λΌμ΄μ–ΈνΈ μ”μ²­
```javascript
// μ›Ή ν”„λ΅ νΈμ—”λ“μ—μ„ μ”μ²­
fetch('http://localhost:1111/api/v1/process', {
  method: 'POST',
  headers: {
    'X-API-Key': 'tlx_xxxxx',  // Gateway μΈμ¦μ©
    'Authorization': 'Bearer eyJxxxxx',  // ν΄λΌμ΄μ–ΈνΈ ν† ν° (MCPμ©)
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    prompt: "μµκ·Ό ν‰κ°€ κ²°κ³Όλ¥Ό λ¶„μ„ν•΄μ£Όμ„Έμ”",
    mcpTools: ["get_appraisals"],  // μ‚¬μ©ν•  MCP λ„κµ¬
    provider: "openai",
    model: "gpt-3.5-turbo"
  })
})
```

### 2οΈβƒ£ Gateway μ²λ¦¬
```typescript
// src/services/orchestrator.ts
class Orchestrator {
  async process(request) {
    // 1. ν΄λΌμ΄μ–ΈνΈ ν† ν°μΌλ΅ MCP μΈμ¦
    await mcpClient.setAuthToken(request.clientToken);
    
    // 2. MCP λ„κµ¬ μ‹¤ν–‰ν•μ—¬ λ°μ΄ν„° μμ§‘
    const mcpData = await this.executeMCPTools(['get_appraisals']);
    
    // 3. μμ§‘λ λ°μ΄ν„°λ¥Ό ν”„λ΅¬ν”„νΈμ— μ¶”κ°€
    const enrichedPrompt = `
      ${request.prompt}
      
      === ν‰κ°€ λ°μ΄ν„° ===
      ${JSON.stringify(mcpData)}
      === λ°μ΄ν„° λ ===
    `;
    
    // 4. LLMμ— μ „λ‹¬ν•μ—¬ λ¶„μ„
    const llmResponse = await llmService.chat('openai', {
      messages: [{ role: 'user', content: enrichedPrompt }]
    });
    
    return { llmResponse, mcpData };
  }
}
```

### 3οΈβƒ£ μ‘λ‹µ κµ¬μ΅°
```json
{
  "llmResponse": {
    "id": "chatcmpl-xxx",
    "choices": [{
      "message": {
        "role": "assistant",
        "content": "ν‰κ°€ κ²°κ³Όλ¥Ό λ¶„μ„ν•΄λ³΄λ©΄..."
      }
    }],
    "usage": {
      "totalTokens": 500
    }
  },
  "mcpData": {
    "get_appraisals": {
      "total_count": 10,
      "appraisals": [...]
    }
  },
  "context": {
    "contextId": "context:1234567890",
    "processingTime": 2500,
    "toolsUsed": ["get_appraisals"]
  },
  "timestamp": "2024-01-12T10:30:00.000Z"
}
```

## π”‘ ν•µμ‹¬ νΉμ§•

### ν† ν° μ¬ν™μ©
- **X-API-Key**: Gateway μμ²΄ μΈμ¦
- **Authorization**: ν΄λΌμ΄μ–ΈνΈ ν† ν°μ„ κ·Έλ€λ΅ MCPμ— μ „λ‹¬
- ν΄λΌμ΄μ–ΈνΈμ κ¶ν•μΌλ΅ MCP λ°μ΄ν„° μ ‘κ·Ό

### λ°μ΄ν„° ν†µν•©
1. MCPμ—μ„ μ‹¤μ‹κ°„ λ°μ΄ν„° μμ§‘
2. ν”„λ΅¬ν”„νΈμ— λ°μ΄ν„° μ£Όμ…
3. LLMμ΄ λ°μ΄ν„° κΈ°λ° μ‘λ‹µ μƒμ„±

### μ»¨ν…μ¤νΈ κ΄€λ¦¬
- κ° μ”μ²­μ μ „μ²΄ μ»¨ν…μ¤νΈ Redis μ €μ¥
- contextIdλ΅ λ‚μ¤‘μ— μ΅°ν κ°€λ¥
- λ€ν™” μ—°μ†μ„± μ μ§€

## π“ API μ—”λ“ν¬μΈνΈ

### ν†µν•© μ²λ¦¬
```
POST /api/v1/process
```
- MCP λ„κµ¬ μ‹¤ν–‰ + LLM μ²λ¦¬
- ν΄λΌμ΄μ–ΈνΈ ν† ν° μ¬ν™μ©
- ν†µν•© μ‘λ‹µ λ°ν™

### λ‹¨μ ν”„λ΅¬ν”„νΈ
```
POST /api/v1/prompt
```
- MCP μ—†μ΄ LLMλ§ μ‚¬μ©
- λΉ λ¥Έ μ‘λ‹µ

### λ„κµ¬ λ©λ΅
```
GET /api/v1/available-tools
```
- ν΄λΌμ΄μ–ΈνΈ ν† ν°μΌλ΅ μ‚¬μ© κ°€λ¥ν• MCP λ„κµ¬ μ΅°ν

### μ»¨ν…μ¤νΈ μ΅°ν
```
GET /api/v1/context/:contextId
```
- μ΄μ „ μ”μ²­μ μ „μ²΄ μ»¨ν…μ¤νΈ μ΅°ν

## π€ μ‹¤ν–‰ μμ‹

### ν‰κ°€ λ°μ΄ν„° λ¶„μ„
```bash
curl -X POST http://localhost:1111/api/v1/process \
  -H "X-API-Key: tlx_xxxxx" \
  -H "Authorization: Bearer eyJxxxxx" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "ν€μ ν‰κ°€ μ μ ν‰κ· κ³Ό νΈλ λ“λ¥Ό λ¶„μ„ν•΄μ£Όμ„Έμ”",
    "mcpTools": ["get_appraisals", "get_response_results"],
    "provider": "openai",
    "model": "gpt-3.5-turbo",
    "temperature": 0.5
  }'
```

### μ¤νΈλ¦¬λ° μ‘λ‹µ
```javascript
const eventSource = new EventSource('http://localhost:1111/api/v1/process');

eventSource.onmessage = (event) => {
  const data = JSON.parse(event.data);
  
  if (data.type === 'mcp_data') {
    console.log('MCP λ°μ΄ν„°:', data.data);
  } else if (data.type === 'llm_chunk') {
    console.log('LLM μ²­ν¬:', data.content);
  }
};
```

## π”’ λ³΄μ• κ³ λ ¤μ‚¬ν•­

1. **μ΄μ¤‘ μΈμ¦**
   - Gateway: API Key (tlx_)
   - MCP: ν΄λΌμ΄μ–ΈνΈ Bearer ν† ν°

2. **ν† ν° κ²©λ¦¬**
   - Gatewayλ” ν† ν° μ „λ‹¬λ§
   - μ‹¤μ  μΈμ¦μ€ MCP μ„λ²„μ—μ„

3. **Rate Limiting**
   - μ‚¬μ©μλ³„ μ”μ²­ μ ν•
   - κ³Όλ„ν• MCP νΈμ¶ λ°©μ§€

## π“ λ¨λ‹ν„°λ§

### λ΅κ·Έ ν™•μΈ
```bash
tail -f logs/combined.log | grep "orchestrator"
```

### Redis λ¨λ‹ν„°λ§
```bash
redis-cli -p 3333
> KEYS context:*
> GET context:1234567890
```

### μ„±λ¥ μ§€ν‘
- MCP λ„κµ¬ μ‹¤ν–‰ μ‹κ°„
- LLM μ‘λ‹µ μ‹κ°„
- μ „μ²΄ μ²λ¦¬ μ‹κ°„
- ν† ν° μ‚¬μ©λ‰

## π― μ‚¬μ© μ‹λ‚λ¦¬μ¤

### 1. μ‹¤μ‹κ°„ λ°μ΄ν„° κΈ°λ° λ¶„μ„
```
ν΄λΌμ΄μ–ΈνΈ: "μµκ·Ό ν‰κ°€μ—μ„ λ†’μ€ μ μλ¥Ό λ°›μ€ μ§μ›λ“¤μ νΉμ§•μ€?"
β†’ MCP: get_appraisals, get_response_results
β†’ LLM: λ°μ΄ν„° λ¶„μ„ λ° μΈμ‚¬μ΄νΈ μ κ³µ
```

### 2. λ§μ¶¤ν• λ¦¬ν¬νΈ μƒμ„±
```
ν΄λΌμ΄μ–ΈνΈ: "μ΄λ² λ¶„κΈ° ν€ μ„±κ³Ό λ¦¬ν¬νΈ μ‘μ„±"
β†’ MCP: μ—¬λ¬ λ„κµ¬λ΅ λ°μ΄ν„° μμ§‘
β†’ LLM: κµ¬μ΅°ν™”λ λ¦¬ν¬νΈ μƒμ„±
```

### 3. μΈν„°λ™ν‹°λΈ Q&A
```
ν΄λΌμ΄μ–ΈνΈ: "ν‰κ°€ μ μκ°€ κ°€μ¥ λ‚®μ€ ν•­λ©μ€?"
β†’ MCP: ν‰κ°€ λ°μ΄ν„° μ΅°ν
β†’ LLM: μμ—°μ–΄λ΅ λ‹µλ³€
```